from pathlib import Path


# ======================================================================
# configuration files
# ======================================================================

# Default to using the config file in the same respository as this 
# Snakefile. Alternatively, you can specify a different config file
# via commandline option `--configfile <path/to/config.yaml>`.
configfile: workflow.source_path('../config/config.yaml')

# This is a separate configuration file that is specific to dataset
# itself, and not to the workflow at all.
#
pepfile: config['input']['pepfile_path']


# ======================================================================
# wildcards
# ======================================================================

# Exclude forward slash in wildcards matching.
# (0) via setting allowed classes of characters
# (1) it's critical to set these regex constrains, to reduce chance of 
#     bad parsing for "ch1/UID1.ome.tif" with pattern 
#     "{ch}/{RoiUID}.ome.tif" to yield wildcard RoiUID = "ch1/UID1"
# (2) this should work globally, EXCEPT FOR inside an glob_wildcards() 
#     call where you need to specify manually! See [related issue](https://github.com/snakemake/snakemake/issues/1726) 
wildcard_constraints:
    RoiUID = "[\w-]+",
    ch = "[\w-]+",
    protocol = "[\w-]+",


def get_channel_names():
    channels = (pep.config['experiments']
                          [config['input']['experiment_type']]
                          ['channels'])
    return [c['fluoro'] for c in channels]
ALL_CH = get_channel_names()


# ======================================================================
# get wildcards from checkpoint
# ======================================================================

#
# This can be used inside an input function, to get {RoiUID}.
#
def get_checkpoint_RoiUID(wildcards):
    checkpoints.crop_roi.get(**wildcards)
    return glob_wildcards("single_nuc_movie/{RoiUID, [\w-]+}.ome.tif").RoiUID


# ======================================================================
# rules
# ======================================================================


#
# these won't be submitted as jobs to the scheduler
#
localrules:
    all,
    all_split_channels,
    all_segment_nuclei,
    all_piv,
    build_imagelist,
    draw_roi,
    crop_roi,
    split_channels,
    gen_piv_config_json,


# -------------------------------------
# the default target rule
# -------------------------------------
rule all:
    input:
        ".all_piv",
        ".all_segment_nuclei",


# -------------------------------------
# other "all" rules to request all outputs from certain rules
# these are convenient especially for rules depending on checkpoint
# -------------------------------------

#
# before checkpoint crop_roi
#

# none

#
# after checkpoint crop_roi
#

rule all_split_channels:
    input:
        lambda w: expand("single_nuc_movie/{ch}/{RoiUID}.ome.tif", 
                         ch=ALL_CH, 
                         RoiUID=get_checkpoint_RoiUID(w))
    output:
        ".all_split_channels"
    shell:
        "touch {output}"


rule all_segment_nuclei:
    input:
        lambda w: expand("single_nuc_mask_movie/{RoiUID}.ome.tif", 
                         RoiUID=get_checkpoint_RoiUID(w))
    output:
        ".all_segment_nuclei"
    shell:
        "touch {output}"


rule all_normalize_intensity:
    input:
        lambda w: expand("normalized_movie/nuc/{RoiUID}.ome.tif",
                         RoiUID=get_checkpoint_RoiUID(w)),
        lambda w: expand("normalized_movie/np/{RoiUID}.ome.tif",
                         RoiUID=get_checkpoint_RoiUID(w)),


rule all_piv:
    input:
        lambda w: expand("piv/{protocol}/{ch}/{RoiUID}.mat",
                         protocol=config['piv']['protocol'],
                         ch=config['piv']['channel'],
                         RoiUID=get_checkpoint_RoiUID(w))
    output:
        ".all_piv"
    shell:
        "touch {output}"


# -------------------------------------
# other rules for target
# -------------------------------------

#
# before checkpoint crop_roi
#

rule draw_roi:
    input: 
        'imagesetlist.csv',
    output:
        'roilist.csv'
    script:
        "scripts/draw_roi.py"

# -------------------------------------
# the rest of other rules
# -------------------------------------

#
# before checkpoint crop_roi
#

rule build_imagelist:
    output: 
        'imagesetlist.csv',
    script:
        "scripts/build_imagelist.py"


# Note:
#   Defining output by touching a file inside the desired output folder
#   (specified same as params.outdir) ensures that folder gets created.
#   This means that the script doesn't need to check/create by itself.
#   We also don't need to explicitly do mkdir before calling the script.
checkpoint crop_roi:
    input:
        'roilist.csv'
    output:
        touch("single_nuc_movie/.done")
    params:
        outdir = "single_nuc_movie"
    resources:
        mem = 1000, 
        time = 30, 
        short_jobs = 1, # <61 minutes
    script:
        "scripts/crop_roi.py"

#
# after checkpoint crop_roi
#

rule split_channels:
    input:
        "single_nuc_movie/{RoiUID}.ome.tif"
    output:
        expand("single_nuc_movie/{ch}/{RoiUID}.ome.tif", 
               ch=ALL_CH, allow_missing=True)
    resources:
        mem = 1000, 
        time = 30, 
        short_jobs = 1, # <61 minutes
    script:
        "scripts/split_channels.py"


rule segment_nuclei_in_time:
    input:
        expand("single_nuc_movie/{ch}/{RoiUID}.ome.tif",
               ch=config['segment_nuclei_in_time']['channel'],
               allow_missing=True)
    output:
        "single_nuc_mask_movie/{RoiUID}.ome.tif"
    resources:
        mem = 2000, 
        time = 61, 
    script:
        "scripts/segment_nuclei_in_time.py"


rule normalize_intensity:
    input:
        image="single_nuc_movie/{RoiUID}.ome.tif",
        mask="single_nuc_mask_movie/{RoiUID}.ome.tif",
    output:
        nuc="normalized_movie/nuc/{RoiUID}.ome.tif",
        np="normalized_movie/np/{RoiUID}.ome.tif",
    params:
        chnames=ALL_CH,
        outdir="normalized_movie/np",
        background=config['normalize_intensity']['background'],
    script:
        "scripts/normalize_intensity.py"


rule gen_piv_config_json:
    output:
        expand("{protocol}_config.json", 
               protocol=config['piv']['protocol'])
    params:
        pivconfig = config['piv']['protocol_configs'][config['piv']['protocol']],
        moviemeta = config['piv']['movie_meta'],
    script:
        "scripts/gen_piv_config_json.py"


rule piv:
    input:
        pivconfig = expand("{protocol}_config.json", 
                           protocol=config['piv']['protocol']),
        movie = "single_nuc_movie/{ch}/{RoiUID}.ome.tif"
    output:
        "piv/{protocol}/{ch}/{RoiUID}.mat"
    params:
        protocol = config['piv']['protocol'],
        pivpkg = str(
            Path(workflow.current_basedir) /
            config['piv']['pkg_path']),
        mfiledir = str(Path(workflow.current_basedir) / "scripts"),
    threads: 1  # While our mfile can use more than one core, somehow
                # snakemake doesn't play well with it and matlab will
                # fail at starting its parpool. 
    envmodules:
        "matlab/R2019b"
    resources:
        mem = 2000, 
        time = 61, 
    shell:
        # Note that in order for {input} {output} to still be relative
        # to dir where Snakemake is invoked, we need to start matlab
        # in the same directory (hence, `-sd <dir/to/launch>` doesn't 
        # fit). 
        """
        matlab -batch "addpath('{params.mfiledir}', genpath('{params.pivpkg}')); {params.protocol}('{input.movie}', '{output}', '{input.pivconfig}', 1)"
        """
